{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7dcc5b9",
   "metadata": {},
   "source": [
    "# Iris Classification Exercise\n",
    "\n",
    "ML exercise using things learned from Google's Crash Course (https://developers.google.com/machine-learning/crash-course) and following the multiclass classification example in Chollet's *Deep Learning with Python*. \n",
    "\n",
    "Iris data retrieved from https://archive.ics.uci.edu/ml/datasets/iris.\n",
    "\n",
    "We create a classification model for iris flowers of three possible species given their sepal length, sepal width, petal length, and petal width.\n",
    "\n",
    "### Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89ed537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd437145",
   "metadata": {},
   "source": [
    "Load the dataframe with 150 total flowers. We set the values of the `species` column in the main dataframe to be represented categorically, and create a one hot encoding for them. The rows in the dataframe are permuted, since the original data is ordered by species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90c81382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "col_names = [\n",
    "    \"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"\n",
    "]\n",
    "categorical_species = {\n",
    "    \"species\" : {\n",
    "        \"Iris-setosa\" : 0,\n",
    "        \"Iris-versicolor\" : 1,\n",
    "        \"Iris-virginica\" : 2\n",
    "    }\n",
    "}\n",
    "\n",
    "main_df = pd.read_csv(\"iris.data\", header=None, names=col_names)\n",
    "main_df = main_df.replace(categorical_species)\n",
    "main_df = main_df.reindex(np.random.permutation(main_df.index))\n",
    "\n",
    "one_hot_species = to_categorical(main_df[\"species\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b045103",
   "metadata": {},
   "source": [
    "### Create test and validation set\n",
    "\n",
    "We create training and test data. 125 are set as training data, and 25 are left for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5341642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = \\\n",
    "        np.array(main_df.iloc[:125, :4].values.tolist()), \\\n",
    "        np.array(main_df.iloc[125:, :4].values.tolist())\n",
    "\n",
    "Y_train, Y_test = \\\n",
    "        np.array(one_hot_species[:125]), \\\n",
    "        np.array(one_hot_species[125:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67489858",
   "metadata": {},
   "source": [
    "Note the shape of our input vectors in `X` and one hot encoded vectors `Y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c62ea1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.8 1.6 0.2]]\n",
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:1])\n",
    "print(Y_train[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a865039",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "\n",
    "Use `Keras` to create a simple sequential model with 20 dimensional intermediate vectors, and a final layer outputting a 3D vector for the one-hot encoded species of iris. Compile the model using the `rmsprop` gradient descent optimization technique, and categorical crossentropy as our loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c30a4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20, activation=\"relu\", input_shape = (4,)))\n",
    "model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b556b",
   "metadata": {},
   "source": [
    "We fit the model to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8297808",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.1984 - accuracy: 0.3520 - val_loss: 1.2061 - val_accuracy: 0.2400\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1108 - accuracy: 0.3520 - val_loss: 1.1070 - val_accuracy: 0.2400\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.0688 - accuracy: 0.3920 - val_loss: 1.0573 - val_accuracy: 0.3600\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0371 - accuracy: 0.5280 - val_loss: 1.0302 - val_accuracy: 0.3600\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0107 - accuracy: 0.5600 - val_loss: 0.9926 - val_accuracy: 0.6800\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9862 - accuracy: 0.7120 - val_loss: 0.9676 - val_accuracy: 0.8400\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.9659 - accuracy: 0.7920 - val_loss: 0.9438 - val_accuracy: 0.8400\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9466 - accuracy: 0.7280 - val_loss: 0.9236 - val_accuracy: 0.8400\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.9239 - accuracy: 0.7760 - val_loss: 0.8989 - val_accuracy: 0.8400\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.9035 - accuracy: 0.7600 - val_loss: 0.8785 - val_accuracy: 0.8400\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8841 - accuracy: 0.7520 - val_loss: 0.8600 - val_accuracy: 0.8400\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8633 - accuracy: 0.8240 - val_loss: 0.8367 - val_accuracy: 0.8400\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8428 - accuracy: 0.8160 - val_loss: 0.8191 - val_accuracy: 0.8400\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8244 - accuracy: 0.8080 - val_loss: 0.7972 - val_accuracy: 0.8400\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8043 - accuracy: 0.8240 - val_loss: 0.7690 - val_accuracy: 0.8400\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7855 - accuracy: 0.8000 - val_loss: 0.7471 - val_accuracy: 0.8400\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7649 - accuracy: 0.7600 - val_loss: 0.7337 - val_accuracy: 0.8400\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7450 - accuracy: 0.8000 - val_loss: 0.7176 - val_accuracy: 0.8400\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7287 - accuracy: 0.8800 - val_loss: 0.6892 - val_accuracy: 0.8400\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7111 - accuracy: 0.8320 - val_loss: 0.6721 - val_accuracy: 0.8400\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.7600 - val_loss: 0.6578 - val_accuracy: 0.8400\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.8400 - val_loss: 0.6345 - val_accuracy: 0.8400\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.8480 - val_loss: 0.6179 - val_accuracy: 0.8400\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.8080 - val_loss: 0.6100 - val_accuracy: 0.8400\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.8240 - val_loss: 0.5982 - val_accuracy: 0.8400\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.9040 - val_loss: 0.5815 - val_accuracy: 0.8400\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.8560 - val_loss: 0.5670 - val_accuracy: 0.8400\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.8800 - val_loss: 0.5590 - val_accuracy: 0.8400\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.9360 - val_loss: 0.5362 - val_accuracy: 0.8400\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.9040 - val_loss: 0.5230 - val_accuracy: 0.8400\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.8480 - val_loss: 0.5178 - val_accuracy: 0.8400\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.9040 - val_loss: 0.5066 - val_accuracy: 0.8400\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.9040 - val_loss: 0.4957 - val_accuracy: 0.8400\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.9360 - val_loss: 0.4891 - val_accuracy: 0.8400\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.9360 - val_loss: 0.4778 - val_accuracy: 0.8400\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.9360 - val_loss: 0.4680 - val_accuracy: 0.8400\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.9600 - val_loss: 0.4612 - val_accuracy: 0.8400\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.9520 - val_loss: 0.4513 - val_accuracy: 0.8400\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.9280 - val_loss: 0.4443 - val_accuracy: 0.8400\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.9520 - val_loss: 0.4436 - val_accuracy: 0.8400\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.9600 - val_loss: 0.4315 - val_accuracy: 0.8400\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.9360 - val_loss: 0.4287 - val_accuracy: 0.8400\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.9520 - val_loss: 0.4187 - val_accuracy: 0.8400\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.9600 - val_loss: 0.4113 - val_accuracy: 0.8400\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.9600 - val_loss: 0.4037 - val_accuracy: 0.8400\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.9440 - val_loss: 0.4035 - val_accuracy: 0.8400\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.9680 - val_loss: 0.4012 - val_accuracy: 0.8400\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.9760 - val_loss: 0.3895 - val_accuracy: 0.8400\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.9680 - val_loss: 0.3842 - val_accuracy: 0.8400\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.9760 - val_loss: 0.3792 - val_accuracy: 0.8400\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.9440 - val_loss: 0.3796 - val_accuracy: 0.8800\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.9840 - val_loss: 0.3700 - val_accuracy: 0.8400\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.9760 - val_loss: 0.3655 - val_accuracy: 0.8400\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.9680 - val_loss: 0.3607 - val_accuracy: 0.8400\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.9760 - val_loss: 0.3618 - val_accuracy: 0.8800\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.9840 - val_loss: 0.3536 - val_accuracy: 0.8400\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.9760 - val_loss: 0.3469 - val_accuracy: 0.8400\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.9760 - val_loss: 0.3435 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.9760 - val_loss: 0.3407 - val_accuracy: 0.8800\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.9920 - val_loss: 0.3348 - val_accuracy: 0.8400\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.9760 - val_loss: 0.3286 - val_accuracy: 0.8400\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.9760 - val_loss: 0.3255 - val_accuracy: 0.8400\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.9840 - val_loss: 0.3289 - val_accuracy: 0.8800\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.9680 - val_loss: 0.3237 - val_accuracy: 0.8800\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.9920 - val_loss: 0.3175 - val_accuracy: 0.8800\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.9920 - val_loss: 0.3129 - val_accuracy: 0.8800\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2850 - accuracy: 0.9920 - val_loss: 0.3104 - val_accuracy: 0.8800\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.9920 - val_loss: 0.3074 - val_accuracy: 0.8800\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.9920 - val_loss: 0.2997 - val_accuracy: 0.8800\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.9920 - val_loss: 0.2984 - val_accuracy: 0.8800\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2641 - accuracy: 0.9760 - val_loss: 0.2914 - val_accuracy: 0.8800\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.9920 - val_loss: 0.2898 - val_accuracy: 0.8800\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.9920 - val_loss: 0.2864 - val_accuracy: 0.8800\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.9920 - val_loss: 0.2824 - val_accuracy: 0.8800\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.9920 - val_loss: 0.2796 - val_accuracy: 0.8800\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.9920 - val_loss: 0.2763 - val_accuracy: 0.8800\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9920 - val_loss: 0.2735 - val_accuracy: 0.8800\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.9920 - val_loss: 0.2716 - val_accuracy: 0.9200\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9920 - val_loss: 0.2678 - val_accuracy: 0.8800\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2276 - accuracy: 0.9920 - val_loss: 0.2650 - val_accuracy: 0.8800\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9920 - val_loss: 0.2621 - val_accuracy: 0.8800\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9920 - val_loss: 0.2598 - val_accuracy: 0.8800\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.9920 - val_loss: 0.2604 - val_accuracy: 0.8800\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.9920 - val_loss: 0.2547 - val_accuracy: 0.8800\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9920 - val_loss: 0.2523 - val_accuracy: 0.9200\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9760 - val_loss: 0.2501 - val_accuracy: 0.9200\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2043 - accuracy: 0.9920 - val_loss: 0.2481 - val_accuracy: 0.9200\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2019 - accuracy: 0.9920 - val_loss: 0.2458 - val_accuracy: 0.9200\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1964 - accuracy: 0.9920 - val_loss: 0.2437 - val_accuracy: 0.9200\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1954 - accuracy: 0.9920 - val_loss: 0.2411 - val_accuracy: 0.9200\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9840 - val_loss: 0.2415 - val_accuracy: 0.8800\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9920 - val_loss: 0.2372 - val_accuracy: 0.9200\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1863 - accuracy: 0.9920 - val_loss: 0.2361 - val_accuracy: 0.9200\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1825 - accuracy: 0.9920 - val_loss: 0.2327 - val_accuracy: 0.9200\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9200\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1781 - accuracy: 0.9920 - val_loss: 0.2316 - val_accuracy: 0.8800\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1779 - accuracy: 0.9920 - val_loss: 0.2272 - val_accuracy: 0.9200\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9920 - val_loss: 0.2263 - val_accuracy: 0.9200\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.9920 - val_loss: 0.2232 - val_accuracy: 0.9600\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1684 - accuracy: 0.9840 - val_loss: 0.2218 - val_accuracy: 0.9200\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1664 - accuracy: 0.9920 - val_loss: 0.2207 - val_accuracy: 0.9200\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1617 - accuracy: 0.9920 - val_loss: 0.2204 - val_accuracy: 0.9200\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.9920 - val_loss: 0.2189 - val_accuracy: 0.9200\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1565 - accuracy: 0.9920 - val_loss: 0.2151 - val_accuracy: 0.9200\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9920 - val_loss: 0.2131 - val_accuracy: 0.9200\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1520 - accuracy: 0.9920 - val_loss: 0.2111 - val_accuracy: 0.9200\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1520 - accuracy: 0.9920 - val_loss: 0.2142 - val_accuracy: 0.9200\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9920 - val_loss: 0.2114 - val_accuracy: 0.9200\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9920 - val_loss: 0.2120 - val_accuracy: 0.9200\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9920 - val_loss: 0.2119 - val_accuracy: 0.9200\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9920 - val_loss: 0.2181 - val_accuracy: 0.8800\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1418 - accuracy: 0.9840 - val_loss: 0.2101 - val_accuracy: 0.9200\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9920 - val_loss: 0.2056 - val_accuracy: 0.9200\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9920 - val_loss: 0.2087 - val_accuracy: 0.9200\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9920 - val_loss: 0.2041 - val_accuracy: 0.9200\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9920 - val_loss: 0.2071 - val_accuracy: 0.9200\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1328 - accuracy: 0.9840 - val_loss: 0.2016 - val_accuracy: 0.9200\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9920 - val_loss: 0.1981 - val_accuracy: 0.9200\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9920 - val_loss: 0.2052 - val_accuracy: 0.9200\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1290 - accuracy: 0.9920 - val_loss: 0.2013 - val_accuracy: 0.9200\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9920 - val_loss: 0.2105 - val_accuracy: 0.8800\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1239 - accuracy: 0.9920 - val_loss: 0.1952 - val_accuracy: 0.9200\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9920 - val_loss: 0.1931 - val_accuracy: 0.9200\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9920 - val_loss: 0.1989 - val_accuracy: 0.9200\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1180 - accuracy: 0.9920 - val_loss: 0.2177 - val_accuracy: 0.8800\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1159 - accuracy: 0.9920 - val_loss: 0.1886 - val_accuracy: 0.9200\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9920 - val_loss: 0.1874 - val_accuracy: 0.9600\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9200\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9920 - val_loss: 0.2013 - val_accuracy: 0.9200\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1119 - accuracy: 0.9920 - val_loss: 0.1990 - val_accuracy: 0.9200\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1112 - accuracy: 0.9920 - val_loss: 0.1890 - val_accuracy: 0.9200\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9920 - val_loss: 0.1852 - val_accuracy: 0.9200\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9920 - val_loss: 0.2000 - val_accuracy: 0.9200\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.9840 - val_loss: 0.1980 - val_accuracy: 0.9200\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.9920 - val_loss: 0.1853 - val_accuracy: 0.9200\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9920 - val_loss: 0.1975 - val_accuracy: 0.9200\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9920 - val_loss: 0.1846 - val_accuracy: 0.9200\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1029 - accuracy: 0.9920 - val_loss: 0.1891 - val_accuracy: 0.9200\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9840 - val_loss: 0.1836 - val_accuracy: 0.9200\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9920 - val_loss: 0.1950 - val_accuracy: 0.9200\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9920 - val_loss: 0.1918 - val_accuracy: 0.9200\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9920 - val_loss: 0.1881 - val_accuracy: 0.9200\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.9920 - val_loss: 0.1887 - val_accuracy: 0.9200\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0956 - accuracy: 0.9920 - val_loss: 0.2052 - val_accuracy: 0.8800\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.9840 - val_loss: 0.1902 - val_accuracy: 0.9200\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0945 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9200\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0927 - accuracy: 0.9840 - val_loss: 0.1897 - val_accuracy: 0.9200\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9920 - val_loss: 0.1952 - val_accuracy: 0.9200\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9920 - val_loss: 0.1871 - val_accuracy: 0.9200\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0915 - accuracy: 0.9920 - val_loss: 0.1920 - val_accuracy: 0.9200\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9920 - val_loss: 0.1854 - val_accuracy: 0.9200\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0895 - accuracy: 0.9840 - val_loss: 0.1997 - val_accuracy: 0.9200\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.9920 - val_loss: 0.1777 - val_accuracy: 0.9200\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9920 - val_loss: 0.1872 - val_accuracy: 0.9200\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9920 - val_loss: 0.1711 - val_accuracy: 0.9200\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9920 - val_loss: 0.1944 - val_accuracy: 0.9200\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9920 - val_loss: 0.1996 - val_accuracy: 0.9200\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9840 - val_loss: 0.1894 - val_accuracy: 0.9200\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9920 - val_loss: 0.1859 - val_accuracy: 0.9200\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9920 - val_loss: 0.1917 - val_accuracy: 0.9200\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9920 - val_loss: 0.1848 - val_accuracy: 0.9200\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0801 - accuracy: 0.9920 - val_loss: 0.1879 - val_accuracy: 0.9200\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9840 - val_loss: 0.1932 - val_accuracy: 0.9200\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9920 - val_loss: 0.1713 - val_accuracy: 0.9200\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9920 - val_loss: 0.1737 - val_accuracy: 0.9200\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.9920 - val_loss: 0.1815 - val_accuracy: 0.9200\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9920 - val_loss: 0.1923 - val_accuracy: 0.9200\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9840 - val_loss: 0.1714 - val_accuracy: 0.9200\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.9840 - val_loss: 0.1908 - val_accuracy: 0.9200\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9920 - val_loss: 0.1870 - val_accuracy: 0.9200\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9920 - val_loss: 0.1763 - val_accuracy: 0.9200\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0744 - accuracy: 0.9920 - val_loss: 0.1889 - val_accuracy: 0.9200\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9920 - val_loss: 0.1714 - val_accuracy: 0.9200\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.9840 - val_loss: 0.1639 - val_accuracy: 0.9600\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9920 - val_loss: 0.1737 - val_accuracy: 0.9200\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9920 - val_loss: 0.2089 - val_accuracy: 0.9200\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9920 - val_loss: 0.2010 - val_accuracy: 0.9200\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9920 - val_loss: 0.1814 - val_accuracy: 0.9200\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9920 - val_loss: 0.2084 - val_accuracy: 0.9200\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9840 - val_loss: 0.1758 - val_accuracy: 0.9200\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9920 - val_loss: 0.1881 - val_accuracy: 0.9200\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9920 - val_loss: 0.2199 - val_accuracy: 0.8800\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9840 - val_loss: 0.1920 - val_accuracy: 0.9200\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9920 - val_loss: 0.2038 - val_accuracy: 0.9200\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9840 - val_loss: 0.1729 - val_accuracy: 0.9200\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.9920 - val_loss: 0.1903 - val_accuracy: 0.9200\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9920 - val_loss: 0.1771 - val_accuracy: 0.9200\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9920 - val_loss: 0.1958 - val_accuracy: 0.9200\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9840 - val_loss: 0.1795 - val_accuracy: 0.9200\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9920 - val_loss: 0.1968 - val_accuracy: 0.9200\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9920 - val_loss: 0.1875 - val_accuracy: 0.9200\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9920 - val_loss: 0.1932 - val_accuracy: 0.9200\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9920 - val_loss: 0.1996 - val_accuracy: 0.9200\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9840 - val_loss: 0.1915 - val_accuracy: 0.9200\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9920 - val_loss: 0.1732 - val_accuracy: 0.9200\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9920 - val_loss: 0.1820 - val_accuracy: 0.9200\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9840 - val_loss: 0.1892 - val_accuracy: 0.9200\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9920 - val_loss: 0.1898 - val_accuracy: 0.9200\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9920 - val_loss: 0.2180 - val_accuracy: 0.8800\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9840 - val_loss: 0.1946 - val_accuracy: 0.9200\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=200,\n",
    "    batch_size=10,\n",
    "    validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fdd7dd",
   "metadata": {},
   "source": [
    "### Visualize training and validation loss\n",
    "\n",
    "Plot the training and validation loss against the number of epochs. Playing around with the model, around 200 epochs the loss began to be constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f8da94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
    "plt.title('model loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283680b1",
   "metadata": {},
   "source": [
    "### Cool!\n",
    "\n",
    "In some permutations, training loss seems to go significantly below validation loss, meaning there is probably some overfitting to the training data occuring. Fortunately, the validation loss seems to converge. Some regularization could be added to the model to fix this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
